## Repository Organization

* Library and Application code in the /neuroport_dbs folder
* Unit tests in the /tests folder. Note this uses the pytest framework and conventions.
* Documentation in the /docs folder

## Maintaining the Documentation

You will need to install several Python packages to maintain the documentation.

* `pip install mkdocs mkdocstrings mknotebooks mkdocs-material Pygments`

The /docs/{top-level-section} folders contain a mix of .md and .ipynb documentation. The latter are converted to .md by the [mknotebooks plugin](https://github.com/greenape/mknotebooks/projects) during building.

Run `mkdocs gh-deploy` to build the documentation, commit to the `gh-deploy` branch, and push to GitHub. This will make the documentation available at https://SachsLab.github.io/NeuroportDBS/

### Autogenerated Documentation

The /docs/neuroport_dbs folder can hold stubs to tell the [mkdocstrings plugin](https://github.com/mkdocstrings/mkdocstrings) to build the API documentation from the docstrings in the library code itself. Currently, this is empty. If any stubs are added then it's necessary to build the documentation from a Python environment that has the package installed. A stub takes the form

```
# Title
::: neuroport_dbs.module.name
```

### Testing the documentation locally

* `mkdocs serve`

If you build the docs locally then you'll also get the /site directory, but this should be git ignored.

## Running the unit tests

TODO

## Development Environment

### Blackrock Neuroport

When using Blackrock hardware, the following tools and SDKs are needed.

The Blackrock NSP has its own [NeuroPort Central Suite](https://www.blackrockmicro.com/technical-support/software-downloads/) to manage the configuration of the device and to store data. However, its data visualization capabilities are rather limited and not suited for DBS MER.

The NSP data stream is accessible via an open source API [CereLink](https://github.com/CerebusOSS/CereLink) which includes a Python interface called `cerebus.cbpy`. These are maintained by Sachs Lab member Chadwick Boulay. Most of our OpenMER software is written in Python and depends on `cerebus.cbpy` and a custom [cerebuswrapper](https://github.com/SachsLab/cerebuswrapper) to communicate with the NSP.

#### nPlayServer

For development, it is useful to playback previously recorded data, without need of hardware or patients.

**Windows**

* Run "C:\Program Files (x86)\Blackrock Microsystems\NeuroPort Windows Suite\runNPlayAndCentral.bat"
* Select a recording to play back
* Use Central's hardware configuration tool to enable continuous recording and spike extraction on the recorded channels.
* Follow the general [Usage Instructions](./usage-instructions.md) with one modification:
    * When running `dbs-ddu`, choose "cbsdk playback" from the dropdown menu to reuse the depths from the recording. The value might not update until the file plays back a change in depth.

**Nix**

* Blackrock does not distribute nPlayServer on macOS or Linux. However, it does exist. Contact Chad directly.
* Central is also unavailable on these platforms. Use `pycbsdk` to quickly change the hardware configuration.

### Playback XDF file

If you have a correctly formatted file, it may be enough to use [XDFStreamer](https://github.com/labstreaminglayer/App-XDFStreamer).

TODO: More instructions needed.

### Dependencies

We assume you know how to work with conda / mamba environments and that you have a MySQL database server running and configured to your liking.

* Create an `openmer` conda environment.
* Install the Python packages from the [table](preparing-distribution.md#required-python-packages).
* Adapt the instructions at [Segmented Electrophys Recordings and Features Database (SERF)](https://github.com/cboulay/SERF) to prepare the database server for your development environment.

## Future goal - installable package

-[] Refactor this repo to exist only as a library
-[] Create a new repo for entry points, leveraging above library, create installer using [fman build system](https://build-system.fman.io/)
